{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344e2c83",
   "metadata": {},
   "source": [
    "# What is an Agent?\n",
    "\n",
    "## Three competing definitions\n",
    "\n",
    "1. AI systems that can do work for you independently - Sam Altman\n",
    "\n",
    "2. A system in which an LLM controls the workflow - Anthropic\n",
    "\n",
    "3. An LLM agent runs tools in a loop to achieve a goal\n",
    "\n",
    "## The third one is the new, emerging definition\n",
    "\n",
    "But what does it mean?\n",
    "\n",
    "Let's make it real.\n",
    "\n",
    "## First up, to demystify 3 concepts:\n",
    "\n",
    "1. Tools - allow an LLM to call a function we write, perhaps to do math, query a database or call an API. Sounds spooky? It's another illusion. LLMs only generate tokens - they can't call functions!\n",
    "\n",
    "2. Structured outputs - require an LLM to respond in JSON according to a particular JSON spec\n",
    "\n",
    "3. Agent Framework - useful code which simplifies (1) and (2), amongst other things, making it easier to connect together LLM calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fda375f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import Agent, Runner, function_tool, set_default_openai_client\n",
    "from dotenv import load_dotenv\n",
    "from rich.console import Console\n",
    "from openai import OpenAI\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2754f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openrouter_url = \"https://openrouter.ai/api/v1/\"\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "openrouter_client = OpenAI(api_key=openrouter_api_key, base_url=openrouter_url)\n",
    "set_default_openai_client(openrouter_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db51f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    agent = Agent(\"Joke teller\", model=\"openai/gpt-4.1-mini\")\n",
    "    result = await Runner.run(agent, \"Tell me a joke for some data scientists\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ed366b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: object Response can't be used in 'await' expression. (request_id: None)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object Response can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m      2\u001b[39m     agent = Agent(\u001b[33m\"\u001b[39m\u001b[33mJoke teller\u001b[39m\u001b[33m\"\u001b[39m, model=\u001b[33m\"\u001b[39m\u001b[33mopenai/gpt-4.1-mini\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(agent, \u001b[33m\"\u001b[39m\u001b[33mTell me a joke for some data scientists\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result.final_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/llm/agentic/.venv/lib/python3.12/site-packages/agents/run.py:343\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, conversation_id, session)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    295\u001b[39m \u001b[33;03mRun a workflow starting at the given agent.\u001b[39;00m\n\u001b[32m    296\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    339\u001b[39m \u001b[33;03m    type of the output.\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    342\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    344\u001b[39m     starting_agent,\n\u001b[32m    345\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    346\u001b[39m     context=context,\n\u001b[32m    347\u001b[39m     max_turns=max_turns,\n\u001b[32m    348\u001b[39m     hooks=hooks,\n\u001b[32m    349\u001b[39m     run_config=run_config,\n\u001b[32m    350\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    351\u001b[39m     conversation_id=conversation_id,\n\u001b[32m    352\u001b[39m     session=session,\n\u001b[32m    353\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/llm/agentic/.venv/lib/python3.12/site-packages/agents/run.py:602\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    597\u001b[39m logger.debug(\n\u001b[32m    598\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    599\u001b[39m )\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    603\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_input_guardrails(\n\u001b[32m    604\u001b[39m             starting_agent,\n\u001b[32m    605\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    606\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    607\u001b[39m             _copy_str_or_list(prepared_input),\n\u001b[32m    608\u001b[39m             context_wrapper,\n\u001b[32m    609\u001b[39m         ),\n\u001b[32m    610\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    611\u001b[39m             agent=current_agent,\n\u001b[32m    612\u001b[39m             all_tools=all_tools,\n\u001b[32m    613\u001b[39m             original_input=original_input,\n\u001b[32m    614\u001b[39m             generated_items=generated_items,\n\u001b[32m    615\u001b[39m             hooks=hooks,\n\u001b[32m    616\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    617\u001b[39m             run_config=run_config,\n\u001b[32m    618\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    619\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    620\u001b[39m             server_conversation_tracker=server_conversation_tracker,\n\u001b[32m    621\u001b[39m         ),\n\u001b[32m    622\u001b[39m     )\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    624\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_single_turn(\n\u001b[32m    625\u001b[39m         agent=current_agent,\n\u001b[32m    626\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    634\u001b[39m         server_conversation_tracker=server_conversation_tracker,\n\u001b[32m    635\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/llm/agentic/.venv/lib/python3.12/site-packages/agents/run.py:1408\u001b[39m, in \u001b[36mAgentRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, server_conversation_tracker)\u001b[39m\n\u001b[32m   1405\u001b[39m     \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m   1406\u001b[39m     \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m-> \u001b[39m\u001b[32m1408\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m   1409\u001b[39m     agent,\n\u001b[32m   1410\u001b[39m     system_prompt,\n\u001b[32m   1411\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1412\u001b[39m     output_schema,\n\u001b[32m   1413\u001b[39m     all_tools,\n\u001b[32m   1414\u001b[39m     handoffs,\n\u001b[32m   1415\u001b[39m     hooks,\n\u001b[32m   1416\u001b[39m     context_wrapper,\n\u001b[32m   1417\u001b[39m     run_config,\n\u001b[32m   1418\u001b[39m     tool_use_tracker,\n\u001b[32m   1419\u001b[39m     server_conversation_tracker,\n\u001b[32m   1420\u001b[39m     prompt_config,\n\u001b[32m   1421\u001b[39m )\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m   1424\u001b[39m     agent=agent,\n\u001b[32m   1425\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1434\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m   1435\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/llm/agentic/.venv/lib/python3.12/site-packages/agents/run.py:1663\u001b[39m, in \u001b[36mAgentRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, hooks, context_wrapper, run_config, tool_use_tracker, server_conversation_tracker, prompt_config)\u001b[39m\n\u001b[32m   1654\u001b[39m previous_response_id = (\n\u001b[32m   1655\u001b[39m     server_conversation_tracker.previous_response_id\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m server_conversation_tracker\n\u001b[32m   1657\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1658\u001b[39m )\n\u001b[32m   1659\u001b[39m conversation_id = (\n\u001b[32m   1660\u001b[39m     server_conversation_tracker.conversation_id \u001b[38;5;28;01mif\u001b[39;00m server_conversation_tracker \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1661\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1663\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m   1664\u001b[39m     system_instructions=filtered.instructions,\n\u001b[32m   1665\u001b[39m     \u001b[38;5;28minput\u001b[39m=filtered.input,\n\u001b[32m   1666\u001b[39m     model_settings=model_settings,\n\u001b[32m   1667\u001b[39m     tools=all_tools,\n\u001b[32m   1668\u001b[39m     output_schema=output_schema,\n\u001b[32m   1669\u001b[39m     handoffs=handoffs,\n\u001b[32m   1670\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m   1671\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m   1672\u001b[39m     ),\n\u001b[32m   1673\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m   1674\u001b[39m     conversation_id=conversation_id,\n\u001b[32m   1675\u001b[39m     prompt=prompt_config,\n\u001b[32m   1676\u001b[39m )\n\u001b[32m   1678\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m   1680\u001b[39m \u001b[38;5;66;03m# If we have run hooks, or if the agent has hooks, we need to call them after the LLM call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/llm/agentic/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:90\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id, conversation_id, prompt)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     91\u001b[39m             system_instructions,\n\u001b[32m     92\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     93\u001b[39m             model_settings,\n\u001b[32m     94\u001b[39m             tools,\n\u001b[32m     95\u001b[39m             output_schema,\n\u001b[32m     96\u001b[39m             handoffs,\n\u001b[32m     97\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m     98\u001b[39m             conversation_id=conversation_id,\n\u001b[32m     99\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    100\u001b[39m             prompt=prompt,\n\u001b[32m    101\u001b[39m         )\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m    104\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/llm/agentic/.venv/lib/python3.12/site-packages/agents/models/openai_responses.py:306\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, conversation_id, stream, prompt)\u001b[39m\n\u001b[32m    302\u001b[39m         response_format = {\u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: model_settings.verbosity}\n\u001b[32m    304\u001b[39m stream_param: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m] | Omit = \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m omit\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    307\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(previous_response_id),\n\u001b[32m    308\u001b[39m     conversation=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(conversation_id),\n\u001b[32m    309\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(system_instructions),\n\u001b[32m    310\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    311\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    312\u001b[39m     include=include,\n\u001b[32m    313\u001b[39m     tools=converted_tools_payload,\n\u001b[32m    314\u001b[39m     prompt=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(prompt),\n\u001b[32m    315\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(model_settings.temperature),\n\u001b[32m    316\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(model_settings.top_p),\n\u001b[32m    317\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(model_settings.truncation),\n\u001b[32m    318\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(model_settings.max_tokens),\n\u001b[32m    319\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    320\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    321\u001b[39m     stream=cast(Any, stream_param),\n\u001b[32m    322\u001b[39m     extra_headers=\u001b[38;5;28mself\u001b[39m._merge_headers(model_settings),\n\u001b[32m    323\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    324\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    325\u001b[39m     text=response_format,\n\u001b[32m    326\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(model_settings.store),\n\u001b[32m    327\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(model_settings.reasoning),\n\u001b[32m    328\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_omit(model_settings.metadata),\n\u001b[32m    329\u001b[39m     **extra_args,\n\u001b[32m    330\u001b[39m )\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Union[Response, AsyncStream[ResponseStreamEvent]], response)\n",
      "\u001b[31mTypeError\u001b[39m: object Response can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12fa8e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?\n",
      "\n",
      "Because she found him mean!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, Runner, set_default_openai_client\n",
    "\n",
    "# Import the actual runner instance the library uses\n",
    "from agents.run import DEFAULT_AGENT_RUNNER\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # 1. Setup the Async OpenRouter client\n",
    "    openrouter_client = AsyncOpenAI(\n",
    "        api_key=os.getenv(\"OPENROUTER_API_KEY\"), base_url=\"https://openrouter.ai/api/v1\"\n",
    "    )\n",
    "\n",
    "    # 2. Force the library to use this client globally\n",
    "    set_default_openai_client(openrouter_client)\n",
    "\n",
    "    # 3. CRITICAL: Manually inject the client into the default runner\n",
    "    # This bypasses the library's internal logic that causes the TypeError\n",
    "    DEFAULT_AGENT_RUNNER.client = openrouter_client\n",
    "\n",
    "    # 4. Define the agent\n",
    "    agent = Agent(\"Joke teller\", model=\"openai/gpt-4o-mini\")\n",
    "\n",
    "    # 5. Run it\n",
    "    result = await Runner.run(agent, \"Tell me a joke for some data scientists\")\n",
    "\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "# Run in Notebook\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\"Joke teller\", model=\"gpt-4.1-mini\")\n",
    "result = await Runner.run(agent, \"Tell me a joke for some data scientists\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = []\n",
    "completed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_todo_report(print: bool=False) -> str:\n",
    "    \"\"\"Get a report of all todos.\"\"\"\n",
    "    result = \"\"\n",
    "    for index, (todo, complete) in enumerate(zip(todos, completed)):\n",
    "        check = \"X\" if complete else \" \"\n",
    "        start = \"[strike][green]\" if complete else \"\"\n",
    "        end = \"[/strike][/green]\" if complete else \"\"\n",
    "        result += f\"Todo #{index + 1}: [{check}] {start}{todo}{end}\\n\"\n",
    "    if print:\n",
    "        Console().print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90852adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_todo_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc82e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_todos(descriptions: list[str]) -> str:\n",
    "    \"\"\"Add new todos from a list of descriptions and return the full list\"\"\"\n",
    "    todos.extend(descriptions)\n",
    "    completed.extend([False] * len(descriptions))\n",
    "    return get_todo_report(print=True)\n",
    "\n",
    "def mark_complete(index: int) -> str:\n",
    "    \"\"\"Mark complete the todo at the given position (starting from 1) and return the full list\"\"\"\n",
    "    if 1 <= index <= len(todos):\n",
    "        completed[index - 1] = True\n",
    "    else:\n",
    "        return \"No todo at this index.\"\n",
    "    return get_todo_report(print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6311520",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos, completed = [], []\n",
    "\n",
    "create_todos([\"Buy groceries\", \"Finish lab1\", \"Go for a walk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c21200",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_complete(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def create_todos(descriptions: list[str]) -> str:\n",
    "    \"\"\"Add new todos from a list of descriptions and return the full list\"\"\"\n",
    "    todos.extend(descriptions)\n",
    "    completed.extend([False] * len(descriptions))\n",
    "    return get_todo_report(print=True)\n",
    "\n",
    "@function_tool\n",
    "def mark_complete(index: int, completion_notes: str) -> str:\n",
    "    \"\"\"Mark complete the todo at the given position (starting from 1) and return the full list\n",
    "    \n",
    "    Args:\n",
    "        index: The 1-based index of the todo to mark as complete\n",
    "        completion_notes: Notes about how you completed the todo in rich console markup\n",
    "    \"\"\"\n",
    "    if 1 <= index <= len(todos):\n",
    "        completed[index - 1] = True\n",
    "    else:\n",
    "        return \"No todo at this index.\"\n",
    "    Console().print(completion_notes)\n",
    "    return get_todo_report(print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_complete.params_json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You are given a problem to solve, by using your todo tools to plan a list of steps, then carrying out each step in turn.\n",
    "Now use the todo list tools, create a plan, carry out the steps, and reply with the solution.\n",
    "Provide your solution in Rich console markup (e.g. [bold red]Error[/bold red]) to indicate colors and styles.\n",
    "Do not ask the user questions or clarification; respond only with the answer after using your tools.\n",
    "\"\"\"\n",
    "tools = [create_todos, mark_complete]\n",
    "agent = Agent(\"Puzzle Agent\", model=\"gpt-4.1-mini\", instructions=instructions, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"A train leaves Boston at 2:00 pm traveling 60 mph. Another train leaves New York at 3:00 pm traveling 80 mph toward Boston. When do they meet?\"\n",
    "todos, completed = [], []\n",
    "response = await Runner.run(agent, task)\n",
    "Console().print(\"\\n\\n\" + response.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053fa87b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
