{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06c733a-1124-44b5-a634-37d0887fdfe6",
   "metadata": {},
   "source": [
    "# The Second Agent - estimate the actual value of a product\n",
    "\n",
    "## RAG (Retrieval Augmented Generation) based on a dataset of 400,000 scraped Amazon products\n",
    "\n",
    "#### For our 2nd agent, we will be asking DeekSeek to estimate the price of one of our deals - and we will give it a hand.\n",
    "\n",
    "It turns out that LLMs are really good at this! Out of the box, GPT-4o is off by an average of \\$76.\n",
    "\n",
    "But we can do even better: we'll provide it with some context, in the form of 5 similar products from our training dataset\n",
    "\n",
    "Again I'll be going quite quickly through this - the idea is for you to run this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db71ba5-55a8-48b7-97d5-9db8dc872837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from litellm import completion\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b044d040-e467-4463-a3a5-119939ca8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "DB = \"products_vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c1cb7f1-41f7-4df8-95fa-f3143b4ce312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Log in to HuggingFace\n",
    "# If you don't have a HuggingFace account, you can set one up for free at www.huggingface.co\n",
    "# And then add the HF_TOKEN to your .env file as explained in the project README\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(token=hf_token, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fbd1f7-619e-49d8-bf1a-209248f1c0e3",
   "metadata": {},
   "source": [
    "# For following along at home:\n",
    "\n",
    "Please download the files train.pkl and test.pkl from this Google Drive folder:  \n",
    "https://drive.google.com/drive/folders/1t0YnoCXCbo2g08uWIOR6TPKR2-6Egb_g?usp=sharing\n",
    "\n",
    "And place them in the parent directory (the directory called agentic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b8a0f3-af5c-4f21-8a5f-a4df4fa420ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "\n",
    "with open('../train.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47116c8f-7e6b-46a0-90ae-ddf8b220bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 400,000 training items scraped from Amazon, and the first one is <Delphi FG0166 Fuel Pump Module = $226.95>\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(train):,} training items scraped from Amazon, and the first one is {train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43f181-8b51-43c8-9763-599220cf6e66",
   "metadata": {},
   "source": [
    "# Now create a Chroma Datastore\n",
    "\n",
    "Now we will use the free, open-source Vector database Chroma.  \n",
    "We will create a Chroma datastore with 400,000 products from our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba77914-ea9a-4b92-9280-863ee07ca8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744c683-847a-4151-b6e0-56066f1fe4b0",
   "metadata": {},
   "source": [
    "# Introducing the SentenceTransformer Encoding LLM\n",
    "\n",
    "The all-MiniLM is a very useful model from HuggingFace that maps sentences & paragraphs to 384 dimensional vectors and is ideal for tasks like semantic search.\n",
    "\n",
    "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "It can run pretty quickly locally.\n",
    "\n",
    "As an alternative, OpenAI provides a closed-source Embeddings model. Benefits compared to OpenAI embeddings:\n",
    "1. It's free and fast!\n",
    "3. We can run it locally, so the data never leaves our box - might be useful if you're building a personal RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9e8a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [\n",
    "    \"That is a happy person\",\n",
    "    \"That is a happy dog\",\n",
    "    \"That is a very happy person\",\n",
    "    \"Today is a sunny day\",\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2545a0-e160-41db-8914-f77b1c7eff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32abb023-64b5-40a4-bfc1-e22c3ec31221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-9.29236319e-03, -2.76716854e-02,  2.08850093e-02,  5.88356331e-03,\n",
       "        1.43282311e-02, -7.71259218e-02,  3.57389748e-02, -1.07448017e-02,\n",
       "       -9.22502764e-03, -1.56571586e-02, -4.24381420e-02, -7.12145343e-02,\n",
       "        5.86078018e-02, -1.77758262e-02, -5.20936064e-02,  6.14698976e-02,\n",
       "       -7.55092409e-03, -8.00909176e-02, -3.97532471e-02, -9.76977423e-02,\n",
       "       -1.56468358e-02,  1.16357766e-02,  1.56349875e-02, -5.24811298e-02,\n",
       "        1.22509815e-03,  9.64261144e-02,  5.03962710e-02, -4.24284264e-02,\n",
       "        6.73197359e-02, -5.70055582e-02,  2.85714846e-02,  3.03971935e-02,\n",
       "        4.60026897e-02,  2.28838939e-02,  5.46884537e-02,  8.03021267e-02,\n",
       "       -4.24176343e-02, -3.81376483e-02,  7.77059495e-02,  1.78595707e-02,\n",
       "       -4.56924327e-02, -1.82922389e-02,  5.41159734e-02, -2.43166331e-02,\n",
       "        5.32313697e-02,  7.15427995e-02, -8.75171460e-03, -1.05135977e-01,\n",
       "        8.65057781e-02, -1.61130447e-02, -9.09638330e-02, -4.96833399e-02,\n",
       "        7.29331980e-03, -2.92307790e-03, -5.44783380e-03,  2.89769322e-02,\n",
       "        5.50012067e-02, -3.92446108e-02,  2.08677864e-03, -2.70764697e-02,\n",
       "        6.17171749e-02, -1.70297716e-02,  7.21124858e-02,  1.99850518e-02,\n",
       "        3.42860469e-03,  2.67654750e-02, -5.70292175e-02,  7.61173740e-02,\n",
       "        2.14246102e-02, -3.56838182e-02,  5.82139865e-02,  5.26138805e-02,\n",
       "        7.85714108e-03,  3.16006131e-02,  9.28160772e-02, -3.59264649e-02,\n",
       "        3.64751020e-03, -6.42962083e-02,  1.32189587e-01, -2.67545730e-02,\n",
       "       -4.25857417e-02, -1.25300944e-01, -6.86371103e-02,  5.51869646e-02,\n",
       "       -4.37720045e-02, -1.16578490e-02,  1.49529558e-02,  1.90595146e-02,\n",
       "        2.98038013e-02,  4.17262502e-02, -3.41776695e-06, -3.68191153e-02,\n",
       "       -7.54120434e-03,  3.09870113e-02,  1.27472222e-01,  8.04523677e-02,\n",
       "       -2.83341259e-02, -7.88779333e-02, -8.01392943e-02,  6.92184642e-02,\n",
       "       -3.02393176e-02,  2.27785204e-02,  2.00580675e-02, -1.44652287e-02,\n",
       "       -1.09465465e-01,  1.78945698e-02,  3.71213779e-02,  2.79406435e-03,\n",
       "        3.46388742e-02, -4.57347631e-02, -2.70138890e-03,  1.01165110e-02,\n",
       "        1.50128426e-02,  2.59222239e-02,  2.18536556e-02, -1.33974962e-02,\n",
       "        5.87786771e-02,  4.77914587e-02,  1.04769133e-02,  4.04592119e-02,\n",
       "        5.15484288e-02, -1.54790580e-02,  1.69143733e-02,  8.33032057e-02,\n",
       "        6.31377175e-02, -1.20919878e-02, -4.85556684e-02, -4.75141061e-33,\n",
       "       -3.51030640e-02,  2.30557397e-02, -7.84298684e-03,  7.77906775e-02,\n",
       "        1.02047555e-01, -4.31146361e-02, -1.51775056e-03,  1.06675401e-01,\n",
       "        2.16376781e-02, -1.38653582e-02, -6.80893362e-02,  3.53952162e-02,\n",
       "       -7.36395046e-02,  5.39285019e-02,  9.06578600e-02, -5.70997335e-02,\n",
       "        2.99870651e-02,  5.83214574e-02, -7.22205862e-02,  9.12528206e-03,\n",
       "       -4.92831552e-03, -7.41257966e-02, -3.05790063e-02,  2.64663510e-02,\n",
       "        2.49995477e-02,  1.77608281e-02,  4.43444923e-02, -9.11166146e-03,\n",
       "        1.02217514e-02,  1.04896808e-02, -9.59612057e-02,  9.68611687e-02,\n",
       "       -5.25418669e-02,  4.33153212e-02, -4.96753938e-02,  4.71268632e-02,\n",
       "       -4.26588207e-02,  4.15426213e-03,  3.06158839e-03,  8.98296535e-02,\n",
       "       -3.85128111e-02,  6.06705956e-02,  4.44481708e-02, -3.10163572e-02,\n",
       "        1.04070259e-02,  1.75866950e-02,  4.43566889e-02, -5.32098711e-02,\n",
       "        3.16898040e-02, -9.75254271e-03, -9.07089189e-02,  2.67113540e-02,\n",
       "       -1.04144476e-02, -7.58788511e-02,  4.09637764e-02, -5.61411977e-02,\n",
       "        3.23858522e-02,  1.13967741e-02,  5.25770262e-02,  4.19577807e-02,\n",
       "       -2.62826402e-02,  9.39249694e-02, -3.06146815e-02,  1.19829431e-01,\n",
       "       -4.63569313e-02,  3.54568809e-02, -3.04606445e-02,  3.90785336e-02,\n",
       "        1.20414898e-01,  6.71364425e-04, -1.00539632e-01, -1.55274896e-02,\n",
       "        9.24696587e-03, -4.75599431e-02, -6.11315705e-02, -9.77276359e-03,\n",
       "       -8.77581388e-02, -3.36544216e-02, -2.00539660e-02, -6.09754808e-02,\n",
       "       -3.46133448e-02,  1.71935651e-02, -5.69767365e-03, -8.71580734e-04,\n",
       "        7.26964697e-02, -1.76525407e-03, -5.13890423e-02,  2.27652881e-02,\n",
       "       -3.34410742e-02,  1.10203950e-02, -5.94769754e-02, -3.86310555e-02,\n",
       "        7.35472608e-03,  2.93824114e-02, -7.67039433e-02,  2.22466898e-33,\n",
       "       -4.63343374e-02,  8.62768665e-03, -1.28885701e-01,  7.42339669e-03,\n",
       "        6.23589605e-02, -2.44938880e-02, -1.70696639e-02, -6.92089088e-03,\n",
       "        4.26500626e-02,  1.06831320e-01, -1.86450984e-02,  3.16983983e-02,\n",
       "        3.51840034e-02, -2.35840585e-03,  6.96647156e-04, -2.31973920e-02,\n",
       "        8.37040916e-02, -5.80954663e-02, -1.90636199e-02,  3.59055512e-02,\n",
       "        4.89160493e-02,  5.56177609e-02, -3.20100039e-02, -5.01170866e-02,\n",
       "        2.72743460e-02,  8.42673779e-02, -4.32173237e-02,  5.31723276e-02,\n",
       "       -2.74440963e-02,  4.92271520e-02, -5.81017360e-02, -5.72873913e-02,\n",
       "       -5.97481318e-02,  7.82730505e-02,  2.42321584e-02, -1.06757302e-02,\n",
       "        3.91537026e-02,  1.10097183e-03, -3.17357443e-02, -5.33479499e-03,\n",
       "        8.43430981e-02, -5.37301302e-02, -7.45497867e-02,  5.33127934e-02,\n",
       "        2.26427894e-03, -5.38990274e-02, -4.04069461e-02, -2.24739406e-02,\n",
       "       -8.93084928e-02, -4.22764905e-02, -5.49092842e-03, -2.73548327e-02,\n",
       "       -1.56643707e-02, -1.21914700e-01, -8.34097415e-02,  2.07737181e-02,\n",
       "       -1.14765698e-02,  3.74961384e-02,  4.67589200e-02,  6.04468361e-02,\n",
       "       -3.51861939e-02, -5.94391301e-02,  3.16112414e-02,  1.94239020e-02,\n",
       "       -1.20718196e-01, -3.37548601e-03,  7.35247508e-03,  7.75729939e-02,\n",
       "       -3.56147103e-02, -2.50113402e-02,  3.82845961e-02,  3.23724821e-02,\n",
       "       -3.80337164e-02,  6.40218109e-02, -1.73387639e-02,  3.05233877e-02,\n",
       "       -1.31783995e-03, -3.14682834e-02,  5.47871254e-02, -2.99820621e-02,\n",
       "       -5.88272698e-02, -6.11703098e-02, -4.71381645e-04,  4.24561538e-02,\n",
       "        1.69677325e-02,  3.37595679e-02, -2.30592359e-02,  3.40376198e-02,\n",
       "        2.43162476e-02, -5.99138811e-03, -1.94647983e-02,  4.29662950e-02,\n",
       "       -1.12587633e-02, -7.60255605e-02, -8.93251002e-02, -1.51147432e-08,\n",
       "       -5.59359193e-02, -5.57127595e-03,  4.95422706e-02, -7.29035179e-04,\n",
       "        2.09761132e-02, -5.64536974e-02, -2.49620359e-02,  3.73166837e-02,\n",
       "        4.75502759e-03, -1.69517733e-02,  1.17230313e-02, -3.48780714e-02,\n",
       "        5.06372191e-02,  5.65097071e-02,  2.85263397e-02,  5.17362505e-02,\n",
       "       -8.03856626e-02,  4.15555388e-02, -4.57120314e-02, -6.05391264e-02,\n",
       "        1.25652716e-01, -2.20339857e-02,  1.53962914e-02,  1.71918925e-02,\n",
       "        1.51212662e-02, -6.73591644e-02, -7.06238598e-02, -4.52953354e-02,\n",
       "       -7.18658268e-02,  8.74663889e-02, -4.14176509e-02,  1.82582736e-02,\n",
       "       -1.19981021e-02,  2.33855899e-02,  1.06364258e-01, -9.78462771e-03,\n",
       "        3.31529230e-02, -5.60202077e-02, -2.67913863e-02, -3.72220296e-03,\n",
       "       -9.42485631e-02, -4.06614430e-02, -1.71347372e-02, -2.51839515e-02,\n",
       "        1.12380899e-01, -9.84920468e-03, -4.72564586e-02, -1.33879423e-01,\n",
       "        3.52699384e-02, -1.19623719e-02,  2.83649620e-02, -2.05238201e-02,\n",
       "       -2.24091373e-02,  1.02427244e-01,  8.28495100e-02,  1.02829589e-02,\n",
       "       -3.19556855e-02, -7.37432837e-02, -8.81814212e-02,  4.31059971e-02,\n",
       "       -6.31511630e-03,  1.07435003e-01, -6.48843870e-02, -9.83754545e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass in a list of texts, get back a numpy array of vectors\n",
    "\n",
    "vector = model.encode([\"A room full of AI engineers\"])[0]\n",
    "print(vector.shape)\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa837b98-17ff-486e-ac30-a4b4f794af7b",
   "metadata": {},
   "source": [
    "## With that background, let's populate our Chroma database\n",
    "\n",
    "### By calculating vectors for 400,000 scraped products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8f101-9c81-462d-be2e-9b479831857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 20/400 [15:32<5:23:37, 51.10s/it]"
     ]
    }
   ],
   "source": [
    "# Check if the collection exists; if not, create it\n",
    "\n",
    "collection_name = \"products\"\n",
    "existing_collection_names = [collection.name for collection in client.list_collections()]\n",
    "\n",
    "if collection_name not in existing_collection_names:\n",
    "    collection = client.create_collection(collection_name)\n",
    "    for i in tqdm(range(0, len(train), 1000)):\n",
    "        documents = [item.text for item in train[i: i+1000]]\n",
    "        vectors = model.encode(documents).astype(float).tolist()\n",
    "        metadatas = [{\"category\": item.category, \"price\": item.price} for item in train[i: i+1000]]\n",
    "        ids = [f\"doc_{j}\" for j in range(i, i+1000)]\n",
    "        collection.add(\n",
    "            ids=ids,\n",
    "            documents=documents,\n",
    "            embeddings=vectors,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "collection = client.get_or_create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65375e1-a8eb-4203-b8f1-dfff69a693cc",
   "metadata": {},
   "source": [
    "# Let's visualize the vectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c3b08-dc89-4995-a25c-041417ec9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is very fun turning this up to 400_000 and seeing the full dataset visualized,\n",
    "# but it almost crashes my box every time so do that at your own risk!! 5_000 is safe!\n",
    "\n",
    "MAXIMUM_DATAPOINTS = 5_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653565a-6405-4c5a-b925-7e14a17bf2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['Appliances', 'Automotive', 'Cell_Phones_and_Accessories', 'Electronics','Musical_Instruments', 'Office_Products', 'Tools_and_Home_Improvement', 'Toys_and_Games']\n",
    "COLORS = ['cyan', 'blue', 'brown', 'orange', 'yellow', 'green' , 'purple', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a754334-69ef-4b4f-92c7-d7da89457f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prework\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'], limit=MAXIMUM_DATAPOINTS)\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "categories = [metadata['category'] for metadata in result['metadatas']]\n",
    "colors = [COLORS[CATEGORIES.index(c)] for c in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30b5e9-7dd9-45c1-a9a7-74cb22cdef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a 2D chart\n",
    "# TSNE stands for t-distributed Stochastic Neighbor Embedding - it's a common technique for reducing dimensionality of data\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a97fc5-9f44-4f1d-a253-8c8f0bcd9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=4, color=colors, opacity=0.7),\n",
    "    text=[f\"Category: {c}<br>Text: {d[:50]}...\" for c, d in zip(categories, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vectorstore Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y'),\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb35e3-bd0d-4569-872b-34bea8316675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try 3D!\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361c151-9f1b-4652-9204-695baf3860d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color=colors, opacity=0.7),\n",
    "    text=[f\"Category: {c}<br>Text: {d[:50]}...\" for c, d in zip(categories, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270b0ad-5a8f-4e54-a852-f16992314e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test pickle file\n",
    "\n",
    "with open('../test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(item):\n",
    "    message = f\"Reply with a 2-3 sentence summary of this product. This will be used to find similar products so it should be clear, concise, complete. Details:\\n{item}\"\n",
    "    messages = [{\"role\": \"user\", \"content\": message}]\n",
    "    response = completion(model=\"groq/openai/gpt-oss-20b\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713cf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c51ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(test[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a25b1-f93c-4a75-9999-09e262f9abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to give some context to GPT-5-mini by selecting 5 products with similar descriptions\n",
    "\n",
    "def make_context(similars, prices):\n",
    "    message = \"For context, here are some other items that might be similar to the item you need to estimate.\\n\\n\"\n",
    "    for similar, price in zip(similars, prices):\n",
    "        message += f\"Potentially related product:\\n{similar}\\nPrice is ${price:.2f}\\n\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b57490-060d-47ff-9cf0-2b61b455bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(item, similars, prices):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = make_context(similars, prices)\n",
    "    user_prompt += \"And now the question for you:\\n\\n\"\n",
    "    user_prompt += item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99ce28-7e42-45df-9aa3-e115332f9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(item):\n",
    "    text = preprocess(item.text)\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471584f-4998-469f-8c7f-cd7ffc74b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similars(item):\n",
    "    vec = vector(item)\n",
    "    results = collection.query(query_embeddings=vec.astype(float).tolist(), n_results=5)\n",
    "    documents = results['documents'][0][:]\n",
    "    prices = [m['price'] for m in results['metadatas'][0][:]]\n",
    "    return documents, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25d64b-655c-4680-8a2a-b4158abf45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, prices = find_similars(test[1])\n",
    "print(make_context(documents, prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700ba02-a84b-432b-896a-29de50b85569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function that extracts a price from a response from GPT-4o-mini\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce59e40-391b-4e52-b190-ef917b2baaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price(\"blah blah the price is $99.99 blah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ab130-b6d8-4356-9704-687c9bc2636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for gpt-5-mini\n",
    "\n",
    "def gpt_4_1_mini_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    response = completion(model=\"gpt-4.1-mini\", messages=messages_for(item, documents, prices), max_tokens=8)\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a6278-2da5-4bf8-b733-2947736feb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much does the Fan Clutch in test[1] actually cost, on Amazon?\n",
    "\n",
    "test[1].price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30586f2-6b84-4750-acf5-a113ac9ccb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's call GPT-4o-mini using RAG, passing in 5 similar items from our Chroma datastore\n",
    "\n",
    "gpt_4_1_mini_rag(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961a9d3-0b59-4523-b555-f29dacd87ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Gemini 2.5 Flash\n",
    "\n",
    "def gemini_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    response = completion(model=\"gemini/gemini-2.5-flash\", messages=messages_for(item, documents, prices), max_tokens=8)\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aaf494-549c-473d-9802-75cc96704e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_rag(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2684714-e6d0-47d6-bf31-87fe349fc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293f0a8-7097-4744-a2e9-7da5268406a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from price_agents.frontier_agent import FrontierAgent\n",
    "\n",
    "agent = FrontierAgent(collection)\n",
    "agent.price(\"Quadcast HyperX condenser mic, connects via usb-c to your computer for crystal clear audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043d5e4-ec42-4fa0-9344-28a856d4f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.price(\"Shure MV7+ professional podcaster microphone with usb-c and XLR outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39799a17-20ad-45ef-8c04-4712f189c9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
